\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[russian]{babel}
\usepackage{multirow}
\usepackage{indentfirst}
\graphicspath{ {./images/} }

\begin{document}
\title{Сравнительный анализ методов классического машинного обучения и ансамблевых алгоритмов для классификации интентов с разным количеством и дисбалансировкой классов}

\maketitle
\section{Ключевые слова}
Искусственный интеллект, машинное обучение, классификация, многоклассовая классификация, обучение с учителем, классическое машинное обучение, ансамблевые методы, логистическая регрессия, метод опорных векторов, наивный Байес, метод k-ближайших соседей, градиентный бустинг, рандомный лес, интенты, диалоговые системы, сбор датасета, предобработка текста, векторизация, параметры выборок, python, sklearn, оценка качества модели

\section{Аннотация}
Данная статья содержит информацию о сравнении методов классического машинного обучения и ансамблевых алгоритмов для классификации интентов с разным количеством классов, элементов класса и коэффициентом сбалансированности. В ходе эксперимента был вручную собран, предобработан и векторизован датасет на основе обучающих выборок классификаторов текстовых и голосовых ботов, обучены и оценены 6 моделей машинного обучения на основе данного датасета и выбран оптимальный классификатор на основе f1-меры для данных условий.

\section{Введение}
Классификаторы, основанные на интентах, являются одними из самых популярных способов NLU в текстовых и голосовых ботах. Однако кроме проблем, связанных с качеством сбора данных для обучающей выборки классификаторов, полноты, репрезентативности и сбалансированности классов, возникают сложности при выборе оптимального классификатора для данных интентов в проекте. В связи с этим возникает потребность в сравнении различных способов классификации интентов для выявления наиболее качественного метода, а также создании алгоритма, который на основе параметров о классах интентов будет определять самый эффективный классификатор. В данной статье будет описана экспериментальная часть, выбор оптимального алгоритма, а также сбор параметров интентов для написания дальнейшего алгоритма по определению необходимого классификатора. 

\section{Постановка задачи}
Целью данного иссследования является проведение сравнительного анализа алгоритмов классического машинного обучения (логистическая регрессия, метод опорных векторов, наивный Байес, метод k-ближайших соседей), а также ансамблевых методов (рандомный лес и градиентный бустинг) для выявления оптимального алгоритма для классификации обучающих выборок интентов для диалоговых систем. В рамках эксперимента будут выполнены следующие задачи: необходимо собрать реальные данные с проектов (выборки обученных интентов), написать функцию парсинга данных в зависимости от конфигурации документов обучающих выборок, сделать предобработку и векторизацию текстов, разделить полученный векторизованный датасет на обучающую и тестовые выборки, обучить вышеупомянутые модели на основе обучающей выборки и оценить качество классификации с помощью метрик (accuracy, precision, recall, f1-мера) на основе тестовой выборки, определить оптимальный алгоритм для многоклассовой классификации интентов. Также необходимо выявить параметры выборки интентов для обучения алгоритма определения оптимального классификатора на основе количества интентов, объема их наполнения и балансировки классов. 

\section{Ограничения}
Данный эксперимент будет проводиться на основе реальных данных на русском языке, выборках интентов, созданных лингвистами-разработчиками для обучения классификаторов текстовых ботов и голосовых ассистентов для коммерческих задач. Учитываются только проекты, которые сделаны благодаря подходу statistical-based (классификация осуществляется с помощью обучения моделей искусственного интеллекта (ИИ)) и mixed-based (классификация осуществляется с помощью гибридного подхода, основанного на комбинировании регулярных выражений и моделей ИИ). Также присутствуют органичения на NLU-язык проекта. Для сбора данных будут учитываться монолингвальные проекты с NLU-языком русским, либо билингвальные проекты, в обучающей выборке интентов которых присутствуют языки различной письменности (например: кириллическая и латинская письменность). В таком случае эти данные могут быть обработаны на этапе препроцессинга с помощью регулярных выражений для извлечения русскоязычных примеров. В случае с билингвальными проектами с языками одинаковой письменности, например русским и узбекским или казахским в кирилической записи, усложняется извлечение примеров на целевом языке, поэтому на данном этапе эксперимента в датасет такие примеры не добавляются. 
Кроме того, учитывается платформа для создания текстовых ботов и голосовых ассистентов. Датасет формируется на основе проектов, написанных на JAICP (Just AI Conversational Platform), диалоговой платформы компании Just AI, так как именно эта платформа содержит как и большее количество промышленных проектов, так и функционал экспорта обучающих выборок интентов в формате *.json для постобработки. Другие платформы в связи с отсутствием данного функционала и последующим усложение ручного сбора данных не рассматриваются. 
Касаемо технических органичений, то обучение и оценка качества моделей проходят с использованием CPU, без графических и тензорных ускорителей. Данное ограничение обусловлено потенциальной коммерциализацией эксперимента для собственной дилоговой платформы, финансовыми и техническими издержками.

\section{Теоретическая часть}
Рассмотрим теоретическую основу используемых нами алгоритмов машинного обучения.

Логистическая регрессия (logistic regression) - это алгоритм, который предсказывает категориальное значение на основе применения сигмоидальной функции к признакам и достижения или не достижения порогового значения функции.

Метод опорных векторов (support vector machine, SVM) - это алгоритм классического машинного обучения, который решает задачи классификации путем создания гиперплоскости, которая будет разделять классы, категориальную метку алгоритм присвает за счет определения направления элемента относительно гиперплоскости. 

Метод к-ближайших соседей (k nearest neighbours, knn) - это алгоритм машинного обучения, который определяет класс, к которому принадлежит элемент, на основе расстояний от тестового элемента до всех элементов тренировочной выборки. Среди множества расстояний определяются k ближайших расстояний, в проводимом эксперименте параметр будет равняться 3. Далее на основании ближайших соседей высчитывается мода и определяется класс.

Наивный Байесовский классификатор (Naive Bayes) - это классификатор, который строится на основании теоремы Байеса:
$$
P(y_{n}|X) = P(y_{n})* P(X|y_{n}) / P(X)
$$
Где $P(y_{n}|X)$ - апостериорная вероятность принадлежности к классу $y_{n}$ с учетом признаков X, 
$P(y_{n})$ - априорная вероятность принадлежности случайно выбранного наблюдения к классу $y_{n}$;
$P(X)$ - это априорная вероятность признаков X.
В данной работе был применен мультиноминальный байесовский классификатор, так как категориальные представления названий интентов являются дискретными признаками с полиноминальным распределением. 

Рандомный лес (random forest) - это алгоритм, который действует по принципу ансамблевого метода, выбирая самое частотно встречающееся предсказание, моду, среди всех деревьев. 

Градиентный бустинг (gradient boosting) - это ансамблевый алгоритм, который основан на применении нескольких деревьев решений и функции бустинга по определению потерь модели на определенной эпохе.


\section{Практическая часть. Сбор данных}
Для решения задачи сбора датасета были выбраны промышленные, тестовые и демо-версии проектов на платформе JAICP, как и текстовые боты, так и голосовые асситенты, созданные на основании статистического и смешанного подходов для классификации запросов пользователей. В первичную выборку попало 95 экспортированных json-файлов, по одному файлу на проект, с обученными интентами на различные тематики (финансовый, инвестиционный и банковский сектор; электронная коммерция; рекрутинг; промышленные и логичестические компании; коллекторские агентства) на русском языке или на двух языках с отличающейся письменностью (русский и латинский узбекский, русский и латинский казахский, русский и английский). Примеры интентов на моголингвальных ботов не на русском языке и билингвальных ботов на двух языках одинаковой письменности в выборку на попали. 
Затем были выбраны 72 документа, размером не менее 4 интентов. Данный подход был обусловлен устранением выбросов выборки и более качественным применением алгоритмов классификации, в частности метода k-ближайших соседей. Итого в собранный вручную датасет вошли 72 документа.  В качестве параметров документов учитывались следующие показатели: общее количество интентов в одном документе, суммарное количество предложений во всех интентах документа, и индекс gini для наполнения интентов документа (количественный индекс, который показывает дисбаланс классов, измеряется по шкале от 0 до 1, где 0 - это максимальный дисбаланс классов, 1 - это максимальный баланс классов, в каждом классе одинаковое количество элементов). Распределение датасета по количеству интентов, предложений и индексу gini: 
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{intents.png}\includegraphics[width=0.5\linewidth]{sentences.png}
    \includegraphics[width=0.5\linewidth]{gini.png}
\end{figure}


\section{Практическая часть. Предобработка данных и векторизация} 
Далее была написана функция парсинга *.json формата документов для извлечения предложений, основе которых были обучены интенты. Данные предложения были предобработаны: были удалены все сторонние символы, кроме символов русского алфавита (цифры, знаки препинания, символы других письменностей) с помощью регулярных выражений, предложения были приведены к нижнему регистру, проведена токенизация, лемматизация полученных токенов с помощью методов библиотеки pymorphy3, были удалены стоп-слова на основе датасета библиотеки nltk. 
В качестве алгоритма векторизации был выбран TF-IDF (term frequency inverse document frequency). Он является самым оптимальным для данной выборки по сравнению с остальными классическими алгоритмами, так как в отличие от bow (bag of words) учитывает не только частоту встречаемости слов во всем тексте, но и семантические отношения между словами, в отличие от word2vec, glove и fasttext не требует большого количества данных для обучения и тонкой настройки параметров.

\section{Практическая часть. Обучение моделей}
Затем векторизированный датасет был разбит на обучующую и тестовую выборки в соотношении 80/20 и были применены модели классического машинного обучения (логичестическая регрессия, метод опорных векторов, k-ближайших соседей, наивный Байес) и ансамблевые методы (градиентный бустинг и рандомный лес) из библиотеки sklearn. Качество моделей оценивалось с помощью следующих метрик: accuracy, precision, recall, f1-мера. Оптимальный алгоритм высчитывался на основе метрики f1, так как она отражает как и полноту, так и точность модели, является средним гармоническим между ними. 
По результатам эксперимента (длительность обучения 72 документов на 6 моделях с использованием CPU составила около 4 часов) наблюдается следующее распределение опттмальных классификаторов.
\begin{center}
\begin{tabular}{| c | c |}
\hline
     \multicolumn{2}{ | c |}{Распределение алгоритмов по частоте максимальной f1-меры} \\
    \hline
     Алгоритм & Количество интентов \\
    \hline
     Random Forest (рандомный лес) & 44 \\ 
     KNN (k-ближайших соседей) & 10 \\  
     SVM (метод опорных векторов) & 7 \\
     Logistic Regression (логистическая регрессия) & 6 \\ 
     Gradient Boosting (градиентный бустинг) & 5 \\  
     Naive Bayes (наивный Байес) & 0 \\
     Итого & 72 \\
    \hline
\end{tabular}
\end{center}

\section{Результаты}
В результате эксперимента был определен самый эффективный алгоритм классификации среди алгоритмов классического машинного обучения и ансамблевых методов, рандомный лес, который показал максимальную f1-меру на выборке из 72 документов с различным количеством классов и коэффициентом их сбалансированности. 

\section{Область применения}
В дальнейшем данные результаты могут быть применены для проектирования диалоговых платформ для создания текстовых ботов и голосовых ассистентов, в частности в отношении выбора более эффективного алгоритма классификации среди классического машинного обучения и ансамблевых методов. 

\section{Дальнейшее развитие}
Сбор датасета и его разметка по следующим параметрам: количество интентов, суммарное количество предложений в каждом интенте, индекс gini помогут в обучении собственного классификатора (классическое машинное обучение, ансамблевые методы, перцептроны, трансформеры) для создания алгоритма автоматического определения наиболее эффективного классификатора на основе входных данные о количестве интентов в проекте. Этот автоматический алгоритм позволит самостоятельно определять наиболее эффективный алгоритм и в дальнейшем использовать его в проекте для классификации интентов. Данная автоматизация поможет снизить риски ухудшения качества классификации интентов при ручном выборе классификатора.
Также планируется расширение списка доступных классификаторов другими алгоритмами искусственного интеллекта кроме классического машинного обучения и ансамблевых методов, а именно нейронными сетями (перцептроном, трансформерами), а также алгоритмами нахождения семантически близких классов благодаря мерам схожести (косинусное расстояние).

\end{document}
